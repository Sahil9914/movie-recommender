{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4747f76",
   "metadata": {},
   "source": [
    "# cell 1 : import libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90c299a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76c55f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv('tmdb_5000_credits.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff3925d",
   "metadata": {},
   "source": [
    "merging Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55382d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.merge(credits,on='title')\n",
    "\n",
    "# Select only the columns we need\n",
    "movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]\n",
    "\n",
    "# Remove any rows with missing information\n",
    "movies.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b10b44",
   "metadata": {},
   "source": [
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aebcbcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast # To safely evaluate string literals\n",
    "\n",
    "# This function will help us extract the names\n",
    "def convert(obj):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        L.append(i['name'])\n",
    "    return L\n",
    "\n",
    "# Apply the function to the 'genres' and 'keywords' columns\n",
    "movies['genres'] = movies['genres'].apply(convert)\n",
    "movies['keywords'] = movies['keywords'].apply(convert)\n",
    "\n",
    "# This function will get the top 3 actors from the 'cast'\n",
    "def convert3(obj):\n",
    "    L = []\n",
    "    counter = 0\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if counter != 3:\n",
    "            L.append(i['name'])\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "    return L\n",
    "\n",
    "movies['cast'] = movies['cast'].apply(convert3)\n",
    "\n",
    "# This function will get only the director's name from the 'crew'\n",
    "def fetch_director(obj):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if i['job'] == 'Director':\n",
    "            L.append(i['name'])\n",
    "            break\n",
    "    return L\n",
    "\n",
    "movies['crew'] = movies['crew'].apply(fetch_director)\n",
    "\n",
    "# Finally, let's split the 'overview' text into a list of words\n",
    "movies['overview'] = movies['overview'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d23b5cf",
   "metadata": {},
   "source": [
    "remove spaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "596bff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove spaces from all names to create unique entities\n",
    "movies['genres'] = movies['genres'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "movies['keywords'] = movies['keywords'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "movies['cast'] = movies['cast'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "movies['crew'] = movies['crew'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "\n",
    "# Combine all the processed lists into a single 'tags' column\n",
    "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a9c91",
   "metadata": {},
   "source": [
    "LAst step of data preprocessing , Final. dayaframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56e4c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final dataframe with just the necessary columns\n",
    "new_df = movies[['movie_id', 'title', 'tags']].copy()\n",
    "\n",
    "# Convert the 'tags' list into a single string\n",
    "new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "# Convert the entire 'tags' string to lowercase\n",
    "new_df['tags'] = new_df['tags'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0494b846",
   "metadata": {},
   "source": [
    "The next step is the most important machine learning part. We need to convert the text in the tags column into numbers (vectors) so that the computer can understand and compare them. This is called Vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2619ce9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the vectorizer\n",
    "# max_features=5000 means we'll take the 5000 most common words\n",
    "# stop_words='english' removes common English words like 'the', 'a', 'in'\n",
    "cv = CountVectorizer(max_features=5000, stop_words='english')\n",
    "\n",
    "# Transform the tags into vectors\n",
    "vectors = cv.fit_transform(new_df['tags']).toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
